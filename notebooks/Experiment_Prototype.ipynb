{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35d75ac1-6315-4c3e-82fd-840d3c838bfd",
   "metadata": {},
   "source": [
    "# To Develop Experiment Py\n",
    "\n",
    "### Functionality\n",
    "Take config, experiment name\n",
    "\n",
    "Return Model & Training Statistics\n",
    "\n",
    "Record Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ff2dfef-5335-4bdb-b9f8-56f7bef9e453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "\n",
    "root_dir = os.path.join(os.getcwd(), \"../..\") # verify its behavior in py file\n",
    "sys.path.append(root_dir)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from src.data.get_dataloader import get_dataloaders\n",
    "from src.model.get_model import get_model\n",
    "from src.visualization.acc_loss import plot_acc_loss\n",
    "from src.model.init_weights import init_weights\n",
    "from src.experiment.utils import one_hot_encode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e7814bc1-970d-423b-83d9-328fd8b7375f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Experiment(object):\n",
    "    \"\"\"\n",
    "    The Experiment Object which\n",
    "    - store dataloader, models, logs\n",
    "    - execute training & testing\n",
    "    - can use other methods to log results to files\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        # Prepare config\n",
    "        try:\n",
    "            config_name = config + \".json\"\n",
    "            config_path = os.path.join(\"../../config\", config_name)\n",
    "        \n",
    "            with open(config_path) as json_file:\n",
    "                self.__config = json.load(json_file)\n",
    "        except Exception as e:\n",
    "            print(\"Error when loading config\")\n",
    "            print(\"Error:\", e)\n",
    "\n",
    "        # prepare device\n",
    "        if torch.cuda.is_available():\n",
    "            self.__device = torch.device('cuda')\n",
    "        elif torch.backends.mps.is_available():\n",
    "            self.__device = torch.device('mps')\n",
    "        else:\n",
    "            self.__device = torch.device('cpu')\n",
    "        print(f'Using device {self.__device}')\n",
    "        # prepare dataloader\n",
    "        self.__train_loader, \\\n",
    "        self.__val_loader, \\\n",
    "        self.__test_loader = get_dataloaders(self.__config)\n",
    "        # prepare model\n",
    "        self.__model = get_model(self.__config)\n",
    "        self.__model = init_weights(self.__config, self.__model)\n",
    "        self.__model.to(self.__device).float()\n",
    "        # prepare criterion\n",
    "        if self.__config['training']['criterion'] == \"cross_entropy\":\n",
    "            self.__criterion = nn.CrossEntropyLoss()\n",
    "        elif self.__config['training']['criterion'] == \"MSE\":\n",
    "            self.__criterion = nn.MSELoss()\n",
    "        else:\n",
    "            raise NotImplementedError(f'Criterion {config[\"training\"][\"criterion\"]} not implemented')\n",
    "        # prepare optimizer\n",
    "        config_optimizer = self.__config['optimizer']\n",
    "        if config_optimizer['type'] == 'adam':\n",
    "            self.__optimizer = torch.optim.Adam(\n",
    "                self.__model.parameters(),\n",
    "                lr = config_optimizer['lr'],\n",
    "                weight_decay = config_optimizer['weight_decay']\n",
    "            )\n",
    "        elif config_optimizer['type'] == 'sgd':\n",
    "            self.__optimizer = torch.optim.SGD(\n",
    "                self.__model.parameters(), \n",
    "                lr=config_optimizer['lr'], \n",
    "                momentum=config_optimizer['momentum'], \n",
    "                weight_decay=config_optimizer['weight_decay'],\n",
    "                nesterov=config_optimizer['nestrov']\n",
    "            )\n",
    "        else:\n",
    "            raise NotImplementedError(f'Optimizer {config_optimizer[\"type\"]} not implemented')\n",
    "        # TODO: prepare LR scheduler\n",
    "\n",
    "        # store the logs\n",
    "        self.__train_losses = []\n",
    "        self.__val_losses = []\n",
    "        self.__train_accs = []\n",
    "        self.__val_accs = []\n",
    "\n",
    "        # util parameters\n",
    "        self.__current_epoch = 0\n",
    "        self.__epochs = self.__config['training']['epochs']\n",
    "\n",
    "    def run(self, run_epochs=None):\n",
    "        print('\\t\\trunning experiment')\n",
    "        start_epoch = self.__current_epoch\n",
    "        if run_epochs != None:\n",
    "            end_epoch = start_epoch + run_epochs\n",
    "        else:\n",
    "            end_epoch = self.__epochs\n",
    "            if start_epoch >= end_epoch:\n",
    "                print(\"Running Epoch over Config Epoch, specify run_epochs for more epochs\")\n",
    "                return\n",
    "\n",
    "        # here we implement the tqdm live progress bar\n",
    "        epoch_describer = tqdm(range(start_epoch, end_epoch), desc=f\"Train\", ncols=100)\n",
    "        live_stats = {\n",
    "            \"describer\": epoch_describer,\n",
    "            \"loss\": [],\n",
    "            \"acc\": []\n",
    "        }\n",
    "        \n",
    "        for epoch in epoch_describer:\n",
    "            self.__current_epoch = epoch\n",
    "            # train\n",
    "            train_loss, train_acc = self.__train(live_stats)\n",
    "            self.__train_losses.append(train_loss)\n",
    "            self.__train_accs.append(train_acc)\n",
    "            # validation\n",
    "            val_loss, val_acc = self.__test(validation=True)\n",
    "            self.__val_losses.append(val_loss)\n",
    "            self.__val_accs.append(val_acc)\n",
    "\n",
    "            # TODO: lr_schedular\n",
    "\n",
    "            epoch_describer.\\\n",
    "                set_description(f\"Train (loss={np.mean(live_stats['loss']):.3f}, acc={np.mean(live_stats['acc']):.3f})\")\n",
    "\n",
    "        test_loss, test_acc = self.__test(validation=False)\n",
    "        \n",
    "        return self.__train_losses, \\\n",
    "            self.__train_accs, \\\n",
    "            self.__val_losses, \\\n",
    "            self.__val_accs, \\\n",
    "            test_loss, \\\n",
    "            test_acc\n",
    "\n",
    "    def __compute_loss_accuracy(self, inputs, labels):\n",
    "        logits = self.__model(inputs)\n",
    "        \n",
    "        if isinstance(self.__criterion, nn.MSELoss):\n",
    "            one_hot_labels = one_hot_encode(\n",
    "                labels, self.__config['data']['num_classes'].to(self.__device)\n",
    "            )\n",
    "            loss = self.__criterion(logits, one_hot_labels)\n",
    "        else:\n",
    "            loss = self.__criterion(logits, labels)\n",
    "            \n",
    "        pred = logits.argmax(dim=1, keepdim=True)\n",
    "        correct = pred.eq(labels.view_as(pred)).sum().item()\n",
    "        return loss, correct\n",
    "\n",
    "    def __train(self, live_stats):\n",
    "        \"\"\"\n",
    "        Perform training over one epoch\n",
    "        \"\"\"\n",
    "        \n",
    "        self.__model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0.0\n",
    "\n",
    "        for inputs, labels in self.__train_loader:\n",
    "            inputs, labels = inputs.to(self.__device), labels.to(self.__device)\n",
    "            loss, correct = self.__compute_loss_accuracy(inputs, labels)\n",
    "            train_loss += loss.detach().cpu().item()\n",
    "            train_correct += correct\n",
    "\n",
    "            # Back Prop\n",
    "            self.__optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.__optimizer.step()\n",
    "\n",
    "            # live stats\n",
    "            current_acc = correct * 100 / len(labels)\n",
    "            live_stats['loss'].append(loss.detach().cpu().item())\n",
    "            live_stats['acc'].append(current_acc)\n",
    "\n",
    "            if len(live_stats['loss']) > 100:\n",
    "                live_stats['loss'].pop(0)\n",
    "                live_stats['acc'].pop(0)\n",
    "\n",
    "            live_stats[\"describer\"].\\\n",
    "                set_description(f\"Train (loss={np.mean(live_stats['loss']):.3f}, acc={np.mean(live_stats['acc']):.3f})\")\n",
    "\n",
    "        # return train_loss and train acc\n",
    "        # (trainloader length = batch #, trainloader.dataset = image #)\n",
    "        return train_loss / len(self.__train_loader), \\\n",
    "                train_correct * 100 / len(self.__train_loader.dataset)\n",
    "\n",
    "\n",
    "    def __test(self, validation=False):\n",
    "        self.__model.eval()\n",
    "        test_loss = 0.0\n",
    "        test_correct = 0.0\n",
    "\n",
    "        if validation == True:\n",
    "            dataloader = self.__val_loader\n",
    "        else:\n",
    "            dataloader = self.__test_loader\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in dataloader:\n",
    "                inputs, labels = inputs.to(self.__device), labels.to(self.__device)\n",
    "                loss, correct = self.__compute_loss_accuracy(inputs, labels)\n",
    "                test_loss += loss.detach().cpu().item()\n",
    "                test_correct += correct\n",
    "\n",
    "        return test_loss / len(dataloader), \\\n",
    "                test_correct * 100 / len(dataloader.dataset)\n",
    "\n",
    "    # Following are some interaction code design\n",
    "    def test_model(self):\n",
    "        return self.__test()\n",
    "                \n",
    "    def get_model(self):\n",
    "        return self.__model\n",
    "\n",
    "    def get_device(self):\n",
    "        return self.__device\n",
    "\n",
    "    def load_model(self, model):\n",
    "        self.__model = model\n",
    "\n",
    "    def get_stats(self):\n",
    "        return self.__train_losses, \\\n",
    "            self.__train_accs, \\\n",
    "            self.__val_losses, \\\n",
    "            self.__val_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "eae01ba1-1a76-421f-a28d-b86ef11c08ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda\n",
      "Creating dataloaders...\n",
      "Dataloaders created\n",
      "Creating model...\n",
      "Model resnet18 created\n"
     ]
    }
   ],
   "source": [
    "exp = Experiment(\"example_config\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "519d6d47-ac6e-4b57-9885-7f425c115e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\trunning experiment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train (loss=0.856, acc=75.000): 100%|█████████████████████████████████| 1/1 [00:20<00:00, 20.33s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.8556607543153966],\n",
       " [74.95625],\n",
       " [0.5172768893341223],\n",
       " [85.575],\n",
       " 0.5122678950428963,\n",
       " 84.99)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.run(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "08c13b4b-fab0-4218-b5f8-8b22423f0757",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.3034055829048157, 10.32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.test_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771015ee-0920-4ad8-8654-703e2bff22d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(config, experiment_name):\n",
    "    \"\"\"\n",
    "    Set up & Run the experiment\n",
    "    \"\"\"\n",
    "\n",
    "    # Prepare config\n",
    "    try:\n",
    "        config_name = config + \"json\"\n",
    "        config_path = os.path.join(\"../../config\", config_name)\n",
    "    \n",
    "        with open(path) as json_file:\n",
    "            config = json.load(json_file)\n",
    "    except Exception as e:\n",
    "        print(\"Error when loading config\")\n",
    "        print(\"Error:\", e)\n",
    "\n",
    "    # prepare dataloader\n",
    "    \n",
    "    model = get_model(config)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e33a8865-90c2-4535-8015-9f3f70f5e34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "root_dir = os.path.join(os.getcwd(), \"../..\") # verify its behavior in py file\n",
    "sys.path.append(root_dir)\n",
    "from src.experiment.Experiment import Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7e259e5-30b9-4faa-89a1-a3db6275e6b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda\n",
      "Creating dataloaders...\n",
      "Dataloaders created\n",
      "Creating model...\n",
      "Model resnet18 created\n"
     ]
    }
   ],
   "source": [
    "exp = Experiment(\"example_config\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68109c94-bb8e-4b09-bea5-cda6cc0fe4bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\trunning experiment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train (loss=0.733, acc=78.925): 100%|█████████████████████████████████| 1/1 [00:20<00:00, 20.66s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.733457919923549],\n",
       " [78.88125],\n",
       " [1.0759052783250809],\n",
       " [64.14166666666667],\n",
       " 1.0351078540086747,\n",
       " 65.68)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.run(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ca90cb-a992-4bc0-a5fd-f02b953a646e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a56ca4df",
   "metadata": {},
   "source": [
    "# ResNet-18 with MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6b7d54",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ced21f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6409d8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06249e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c2efda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a0bf2ce",
   "metadata": {},
   "source": [
    "## Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fea10735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configs\n",
    "config = {\n",
    "    \"data\": {\n",
    "        \"path\": \"../data\",\n",
    "        \"in_channels\": 1,\n",
    "        \"num_classes\": 10,\n",
    "        \"batch_size\": 512\n",
    "    },\n",
    "    \"model\": {\n",
    "        \n",
    "    },\n",
    "    \"training\":{\n",
    "        \"learning_rate\": 1e-5,\n",
    "        \"optimizer\": \"sgd\",\n",
    "        \"epochs\": 5\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e549f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd213911",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc7605d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform for MNIST \n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,)) # specific for MNIST\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5abb4e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████| 9912422/9912422 [00:00<00:00, 57797747.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████| 28881/28881 [00:00<00:00, 26396969.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████| 1648877/1648877 [00:00<00:00, 27105729.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 4542/4542 [00:00<00:00, 4836387.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root = config['data']['path'],\n",
    "    train = True,\n",
    "    transform = transform,\n",
    "    download = False\n",
    ")\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root = config['data']['path'],\n",
    "    train = False,\n",
    "    transform = transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5f2e140",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset = train_dataset,\n",
    "    batch_size = config['data']['batch_size'],\n",
    "    shuffle = True\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset = test_dataset,\n",
    "    batch_size = config['data']['batch_size'],\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d78d76f",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65b43f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "    \n",
    "    def __init__(self, in_channels, channels, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.expansion = 1\n",
    "        self.conv1 = nn.Conv2d(in_channels, channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(channels)\n",
    "        self.conv2 = nn.Conv2d(channels, channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(channels)\n",
    "        \n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != self.expansion*channels:\n",
    "            # modify shortcut for correct channel output\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, self.expansion*channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion * channels)\n",
    "            )\n",
    "            \n",
    "    def forward(self, x):\n",
    "        out = nn.ReLU()(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = nn.ReLU()(out)\n",
    "        return out\n",
    "    \n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, in_channels, num_classes):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.in_channels = 64 # modify as it after first channel\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
    "        \n",
    "        \n",
    "    def _make_layer(self, block, channels, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        \n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_channels, channels, stride))\n",
    "            self.in_channels = channels * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = nn.ReLU()(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = nn.AdaptiveAvgPool2d(1)(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80f4edcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet(\n",
    "    BasicBlock, \n",
    "    num_blocks = [2, 2, 2, 2], \n",
    "    in_channels = config['data']['in_channels'],\n",
    "    num_classes = config['data']['num_classes']\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9871830c",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c358a375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions for training\n",
    "def calculate_acc(logits, labels):\n",
    "    \"\"\"\n",
    "    Given logits and correct labels:\n",
    "    Return number of corrections and accuracy\n",
    "    \"\"\"\n",
    "    pred = logits.argmax(dim=1, keepdim=True)\n",
    "    correct = pred.eq(labels.view_as(pred)).sum().detach().cpu().item()\n",
    "    return correct, 100 * correct / len(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82854e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "if config['training']['optimizer'] == 'sgd':\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config['training']['learning_rate']) \n",
    "elif config['training']['topmizer'] == 'adam':\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=config['training']['learning_rate'])\n",
    "# lr_scheduler = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be9914a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 [loss:0.04, acc:99.28]: 100%|█████████████████████████████████| 5/5 [02:38<00:00, 31.68s/it]\n"
     ]
    }
   ],
   "source": [
    "# TRAINING\n",
    "\n",
    "# Assitant List for showing live loss/acc\n",
    "live_losses = []\n",
    "live_accs = []\n",
    "\n",
    "epoch_describer = tqdm(range(config['training']['epochs']), desc=f\"Epoch {1}\", ncols=100)\n",
    "\n",
    "training_losses = []\n",
    "training_accs = []\n",
    "validation_losses = []\n",
    "validation_accs = []\n",
    "    \n",
    "for epoch in epoch_describer:\n",
    "    \n",
    "    training_loss = 0.0\n",
    "    training_corr = 0.0\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        correct, accuracy = calculate_acc(outputs, labels)\n",
    "        \n",
    "        training_corr += correct\n",
    "        training_loss += loss.detach().cpu().item()\n",
    "        \n",
    "        live_losses.append(loss.detach().cpu().item())\n",
    "        live_accs.append(accuracy)\n",
    "        if len(live_losses) > 100:\n",
    "            live_losses.pop(0)\n",
    "            live_accs.pop(0)\n",
    "            \n",
    "        # update \n",
    "        epoch_describer.\\\n",
    "        set_description(f\"Epoch {epoch+1} [loss:{np.mean(live_losses):.2f}, acc:{np.mean(live_accs):.2f}]\")\n",
    "        \n",
    "    # record training data per epoch\n",
    "    training_losses.append(training_loss / len(train_loader))\n",
    "    training_accs.append(training_corr / len(train_loader.dataset))\n",
    "        \n",
    "    # validate the result\n",
    "    valid_loss = 0.0\n",
    "    valid_corr = 0.0\n",
    "    \n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            correct, accuracy = calculate_acc(outputs, labels)\n",
    "            \n",
    "            valid_loss += loss.detach().cpu().item()\n",
    "            valid_corr += correct\n",
    "            \n",
    "    validation_losses.append(valid_loss / len(test_loader))\n",
    "    validation_accs.append(valid_corr / len(test_loader.dataset))                                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb89c190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7413833333333333,\n",
       " 0.9613166666666667,\n",
       " 0.97995,\n",
       " 0.9874166666666667,\n",
       " 0.9926666666666667]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "45d70d77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9458, 0.9736, 0.9814, 0.9854, 0.9868]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_accs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
